'''
Joshua Meyer

Simulating a Hidden Markov Model

USAGE: $ python3 hmm.py
'''
import numpy as np
import random

class HMM:
    def __init__(self):
        # look-up tables for emissions and states
        self.S = ['state1','state2','state3']
        self.K = ['a', 'b']
        
        # array of initial state probabilities
        self.PI = np.matrix([1.0,
                             0.0,
                             0.0],
                            dtype=float)

        # matrix of state transition probabilities
        # where each row = FROM_STATE
        # and each column = TO_STATE
        self.A = np.matrix([[0.2, 0.4, 0.4],
                            [0.1, 0.2, 0.7],
                            [0.7, 0.2, 0.1]],
                           dtype=float)


        # matrix of emission probabilities
        # where each row = STATE
        # and each column = EMISSION
        self.B = np.matrix([[0.4, 0.6],
                            [0.1, 0.9],
                            [0.2, 0.8]],
                           dtype=float)

        
    def forward_algorithm(self, O):
        '''
        Given some input string O, calculate the probability that
        it was generated by the HMM (specs in __init__).

        INITIALIZATION:
        \alpha_1(j) = a_{oj} \cdot b_j(o_1) for each state j
        
        FOR CALCULATING ONE CELL RECURSIVELY (ie, after initialization):
        \alpha_{t}(j) = \sum^{N}_{i=1} \big[ \alpha_{t-1}(i) \cdot a_{ij} \cdot b_j(o_t) \big]

        WHERE:
        \alpha_{t-1}(i) = the previous forward path probability for STATE_i in the previous time step
        a_{ij} = the transition probability from the previous STATE_i to the current STATE_j
        b_j(o_t) = the probability of emitting observation O_t at STATE_j
        '''
        # create matrix to hold local probailities
        Trellis = np.zeros((len(self.S),len(O)),dtype=float)

        # for each emission in the input observation
        for emission_num, emission in enumerate(O):

            emissionIndex = self.K.index(emission)

            # INITIALIZATION
            if emission_num == 0:
                # \alpha_1(j) = a_{oj} \cdot b_j(o_1) for each state j
                for state_j in range(len(self.S)):
                    initialProb_j = self.PI[0,state_j]
                    emissionProb_j = self.B[state_j,emissionIndex]
                    alpha1_j = initialProb_j*emissionProb_j
                    Trellis[state_j,0] = alpha1_j

            # RECURSION
            elif emission_num != 0:
                # \alpha_{t}(j) = \sum^{N}_{i=1} \big[ \alpha_{t-1}(i) \cdot a_{ij} \cdot b_j(o_t) \big]
                for state_j in range(len(self.S)):
                    combinedProb_j = 0
                    emissionProb_j = self.B[state_j,emissionIndex]

                    for state_i in range(len(self.S)):
                        previousProb_i = Trellis[state_i,(emission_num-1)]
                        transProb_ij = self.A[state_i,state_j]
                        combinedProb_j += previousProb_i*transProb_ij*emissionProb_j

                    Trellis[state_j,emission_num] = combinedProb_j

        return Trellis

    def compute_max_likelihood(self, O):
        Trellis = self.forward_algorithm(O)
        MLE = np.sum(Trellis, axis=0)[-1]
        print('FORWARD ALGORITHM TRELLIS:')
        print(Trellis)
        print('MAXIMUM LIKELIHOOD ESTIMATION:')
        print(O, str(MLE))
        

    def viterbi_algorithm(self, O):
        '''
        Given some input string O, calculate the probability that
        it was generated by the HMM via Viterbi (specs in __init__).

        INITIALIZATION:
        \alpha_1(j) = a_{oj} \cdot b_j(o_1) for each state j
        
        FOR CALCULATING ONE CELL RECURSIVELY (ie, after initialization):
        \alpha_{t}(j) = \max^{N}_{i=1} \big[ \alpha_{t-1}(i) \cdot a_{ij} \cdot b_j(o_t) \big]

        WHERE:
        \alpha_{t-1}(i) = the previous forward path probability for STATE_i in the previous time step
        a_{ij} = the transition probability from the previous STATE_i to the current STATE_j
        b_j(o_t) = the probability of emitting observation O_t at STATE_j
        '''
        # create matrix to hold local probailities
        Trellis = np.zeros((len(self.S),len(O)),dtype=float)

        # for each emission in the input observation
        for emission_num, emission in enumerate(O):

            emissionIndex = self.K.index(emission)

            # INITIALIZATION
            if emission_num == 0:
                # \alpha_1(j) = a_{oj} \cdot b_j(o_1) for each state j
                for state_j in range(len(self.S)):
                    initialProb_j = self.PI[0,state_j]
                    emissionProb_j = self.B[state_j,emissionIndex]
                    alpha1_j = initialProb_j*emissionProb_j
                    Trellis[state_j,0] = alpha1_j

            # RECURSION
            elif emission_num != 0:
                # \alpha_{t}(j) = \max^{N}_{i=1} \big[ \alpha_{t-1}(i) \cdot a_{ij} \cdot b_j(o_t) \big]
                for state_j in range(len(self.S)):
                    bestProb_j = 0
                    currentProb_j = 0
                    emissionProb_j = self.B[state_j,emissionIndex]
                    for state_i in range(len(self.S)):
                        previousProb_i = Trellis[state_i,(emission_num-1)]
                        transProb_ij = self.A[state_i,state_j]
                        currentProb_j = previousProb_i*transProb_ij*emissionProb_j
                        if bestProb_j < currentProb_j:
                            bestProb_j = currentProb_j
                    Trellis[state_j,emission_num] = bestProb_j

        return Trellis


    def compute_viterbi(self, O):
        Trellis = self.viterbi_algorithm(O)
        prob = np.max(Trellis, axis=0)[-1]
        print('VITERBI TRELLIS:')
        print(Trellis)
        print('VITERBI PROBABILITY:')
        print(O, str(prob))

def cartesian_product(arrays, cartesianProdArray=None):
    """
    Generate a cartesian product of input arrays.

    INPUT
    arrays : list of array-like
        1-D arrays to form the cartesian product of.
    cartesianProdArray : ndarray
        Array to place the cartesian product in.

    OUTPUT
    cartesianProdArray : ndarray
        2-D array of shape (M, len(arrays)) containing cartesian products
        formed of input arrays.

    EXAMPLE
    >>> cartesian(([1], [4, 5], [6, 7]))
    array([[1, 4, 6],
           [1, 4, 7],
           [1, 5, 6],
           [1, 5, 7]])
    """
    # take the input (array_like: lists, tuples, matrices) and convert to array
    arrays = [np.asarray(x) for x in arrays]
    # take the datatype from the first of the arrays
    dtype = arrays[0].dtype

    # find the length of the output array
    n = np.prod([x.size for x in arrays])
    # initialize empty array
    if cartesianProdArray is None:
        cartesianProdArray = np.zeros([n, len(arrays)], dtype=dtype)

    m = n / arrays[0].size
    cartesianProdArray[:,0] = np.repeat(arrays[0], m)
    if arrays[1:]:
        cartesian_product(arrays[1:],
                          cartesianProdArray=cartesianProdArray[0:m,1:])
        for j in range(1, arrays[0].size):
            cartesianProdArray[j*m:(j+1)*m,1:] = cartesianProdArray[0:m,1:]
    return cartesianProdArray


def generate_string(hmm):
    len1sentences = cartesian_product([hmm.K]*1)
    len2sentences = cartesian_product([hmm.K]*2)
    len3sentences = cartesian_product([hmm.K]*3)

    for sentences in [len1sentences,len2sentences,len3sentences]:
        for sentence in sentences:
            Trellis = hmm.forward_algorithm(sentence)
            states, probs = hmm.get_best_path(Trellis)

            tags = (' ').join(states)
            sentence = ('').join(np.array(sentence))
            jointProb = np.prod(probs)
            # latex booktabs format
            tableLine = (sentence+'\t& '+tags+'\t& '+str(jointProb)+r'\\')
            print(tableLine)


            
if __name__ == "__main__":
    hmm = HMM()
    print('STATES:')
    print(hmm.S)
    print('ALPHABET:')
    print(hmm.K)
    o = input('Enter observation here with spaces: ')
    o = o.split(' ')
    hmm.compute_max_likelihood(o)
    hmm.compute_viterbi(o)
